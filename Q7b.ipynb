{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1-Q8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVVeVEgumZLg"
      },
      "source": [
        "# CE-40959: Deep Learning\n",
        "## HW1\n",
        "## Q8\n",
        "#### Name:\n",
        "#### Student No.:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5alOnjtlGfy"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGj-LMuWmx2q"
      },
      "source": [
        "#### 3.1. Load Data:\n",
        "\n",
        "Complete the followed cell for data loading. \n",
        "In this cell you have to normalize, split and shuffle data for learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgv51um_lJiL"
      },
      "source": [
        "trainloader = None\n",
        "validationloader = None\n",
        "testloader = None\n",
        "##################################################################################\n",
        "# TODO: Use 'torchvision.datasets.FashionMNIST' class for loading FashionMNIST   #\n",
        "# dataset. This dataset has 50000 data for training and 10000 data for test      #\n",
        "# and every data has shape (1*28*28).                                            #\n",
        "# Also Use 'torchvision.transforms.Compose' for common image transformations     #\n",
        "# such as normalization and use 'torch.utils.data.DataLoader' class that it      #\n",
        "# represents a Python iterable over a dataset and divides data to Batches.       #\n",
        "# Then Split data into 3 part: Train, Validation and Test. Finally,              #\n",
        "# save iterable data in 'trainloader', 'validationloader', 'testloader'.         #\n",
        "##################################################################################\n",
        "batch_size_train = None\n",
        "batch_size_test =  None\n",
        "##################################################################################\n",
        "#                               End of your code                                 #\n",
        "##################################################################################\n",
        "\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdLQ8BpxEoZ-"
      },
      "source": [
        "#### 3.2. Load Data Test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaOeLN3klZ9F"
      },
      "source": [
        "############################################################\n",
        "# Run the following code an check the size of each batch   #\n",
        "############################################################\n",
        "examples = enumerate(trainloader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "print('The size and type of each batch in ''trainloader'' is:')\n",
        "print(example_data.size())\n",
        "print(type(example_data))\n",
        "examples = enumerate(testloader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "print('\\nThe size and type of each batch in ''testloader'' is:')\n",
        "print(example_data.size())\n",
        "print(type(example_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPMpTd230hLY"
      },
      "source": [
        "#####################################################################\n",
        "# Run the following code and see some of the samples in the dataset #\n",
        "#####################################################################\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images:\n",
        "for i in range(4):\n",
        "    img=torchvision.utils.make_grid(images[i])\n",
        "    ###########################################################\n",
        "    #  If you normalize data , here unnormalize them to see   # \n",
        "    #  clear them.                                            #\n",
        "    ###########################################################\n",
        "    m=None\n",
        "    s=None\n",
        "    img = img*s + m    # unnormalize\n",
        "    ###########################################################\n",
        "    #                   End of your code                      #\n",
        "    ###########################################################\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2, 0)))\n",
        "    plt.title(\"Target Labels: {}\".format(classes[labels[i]]))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKpijVi0E1Zm"
      },
      "source": [
        "#### 3.3. Network Design:\n",
        "Design the layer of your network and select proper hyperparameter. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8nfR7jqxTBO"
      },
      "source": [
        "######################################################################\n",
        "# TODO: Use 'torch.nn' module to design your network for CIFAR-10    #\n",
        "# classification. You have to implement the structure of MLP for it. #\n",
        "# In your design you don't have any limitation and you can use       #\n",
        "# Batch-norm layers, Drop-out layers and etc for generalization      #\n",
        "# improvement (if needed). Use classes and modules from 'torch.nn'.  #\n",
        "# In the following code, the 'MLP' class is your MLP network and     #\n",
        "# this class is inherited from nn.Module, so you can benefit         #\n",
        "# properties of the 'nn.Module'.You may complete '__init__()'        #\n",
        "# constructor by some classes like 'nn.ReLU()' or 'nn.Linear()'      #\n",
        "# to use them in the forward pass of your network.                   #\n",
        "######################################################################\n",
        "  \n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, hidden_dim=150, keep_prob = 0.2):\n",
        "        super(MLP, self).__init__()\n",
        "        # todo\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # todo\n",
        "        pass\n",
        "        return out\n",
        "\n",
        "######################################################################\n",
        "#                          End of your code                          #\n",
        "######################################################################"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dGyL8c8E-Rb"
      },
      "source": [
        "#### 3.4. Optimization Algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXuefQ1GB7Ry"
      },
      "source": [
        "#############################################################################\n",
        "# TODO:                                                                     #\n",
        "# 1- use classification cross-entropy loss                                  #\n",
        "# 2- use 'torch.optim' module for optimization                              #\n",
        "# 3- select optimization algorithm and its hyperparameter                   #\n",
        "#############################################################################\n",
        "net = MLP()\n",
        "learning_rate = None\n",
        "criterion = None\n",
        "optimizer = None\n",
        "#############################################################################\n",
        "#                             End of your code                              #\n",
        "#############################################################################"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jL9GEnZFN-z"
      },
      "source": [
        "#### 3.5. Training:\n",
        "You have to tweak `hidden_dim`, `leanirng_rate`, `weight_scale`, `num_epochs` and `reg` and etc to get a validation accuracy above 50%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJdyD46TZY0t"
      },
      "source": [
        "#######################################################\n",
        "# TODO: Feed the inputs data to the MLP network and   #\n",
        "# optimize Cross-Entropy loss by using target labels. #\n",
        "# Then update weights and biases.                     #\n",
        "#######################################################\n",
        "\n",
        "num_epochs=25\n",
        "num_batchs = len(trainloader)\n",
        "for epoch in range(num_epochs):\n",
        "    total_train=0\n",
        "    correct_train=0\n",
        "    running_loss = 0.0\n",
        "    for batch, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients:\n",
        "        pass\n",
        "\n",
        "        # forward pass:\n",
        "        pass\n",
        "\n",
        "        # backward pass:\n",
        "        pass\n",
        "\n",
        "        # optimization:\n",
        "        pass\n",
        "        #############################################\n",
        "        #           End of your code                #\n",
        "        #############################################\n",
        "        \n",
        "\n",
        "        # Results: \n",
        "        running_loss += loss.item()\n",
        "\n",
        "        total_train += labels.size(0)\n",
        "        _, predicted_train = torch.max(outputs.data, 1)\n",
        "        correct_train += (predicted_train == labels.to(device)).sum().item()\n",
        "\n",
        "        if batch % (num_batchs/10) == ((num_batchs/10) -1):\n",
        "            print('[Batch %d / %d] loss: %.3f' %\n",
        "                  (batch + 1, num_batchs, running_loss / (num_batchs/10)))\n",
        "            running_loss = 0.0\n",
        "            torch.save(net.state_dict(), './model.pth')\n",
        "            torch.save(optimizer.state_dict(), './optimizer.pth')\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in validationloader:\n",
        "            images, labels = data\n",
        "            outputs = net(images.to(device))\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels.to(device)).sum().item()\n",
        "    val_acc = correct / total\n",
        "    train_acc = correct_train / total_train\n",
        "    print('(Epoch %d / %d) train acc: %.2f%%; val_acc: %.2f%%' % (\n",
        "          epoch+1, num_epochs, 100*train_acc, 100*val_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLES_37SM6_N"
      },
      "source": [
        "#### 3.6. Test: \n",
        "Run the following cell and test your network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw4zW0GPM6cR"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images.to(device))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.to(device)).sum().item()\n",
        "test_acc = correct / total\n",
        "print('Accuracy of the network on the test images: %2f %%' % (100 * test_acc ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrnQkpyENTrR"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images.to(device))\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels.to(device)).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}